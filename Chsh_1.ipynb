{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "330b08a2-fc1d-4403-924b-7bc3eb5e9415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce089a75-377a-4d4a-b7e9-7bcfb1475f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = np.array([[1, 0], [0, 0]])\n",
    "\n",
    "# Selecting the device\n",
    "dev = qml.device(\"default.mixed\", wires=3)\n",
    "\n",
    "# Function to create the CHSH observables\n",
    "def create_observable(theta, phi):\n",
    "    return np.array([[np.cos(theta), np.exp(-1j * phi) * np.sin(theta)],\n",
    "                     [np.exp(1j * phi) * np.sin(theta), -np.cos(theta)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f80fa66-7106-4e19-91a0-8b52217c8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bell_pair(params,p):\n",
    "    qml.Hadamard(wires=0)\n",
    "    qml.CNOT(wires=[0,1])\n",
    "    qml.U3(params[0],params[1],params[2],wires=1)\n",
    "    qml.U3(params[3],params[4],params[5],wires=2)\n",
    "    qml.CNOT(wires=[2,1])\n",
    "    qml.RZ(params[6],wires=1)\n",
    "    qml.RY(params[7],wires=2)\n",
    "    qml.CNOT(wires=[1,2])\n",
    "    qml.RY(params[8],wires=2)\n",
    "    qml.CNOT(wires=[2,1])\n",
    "    qml.U3(params[9],params[10],params[11],wires=1)\n",
    "    qml.U3(params[12],params[13],params[14],wires=2)\n",
    "    qml.DepolarizingChannel(1-p,wires=1)\n",
    "    qml.DepolarizingChannel(1-p,wires=2)\n",
    "    qml.adjoint(qml.U3(params[12],params[13],params[14],wires=2))\n",
    "    qml.adjoint(qml.U3(params[9],params[10],params[11],wires=1))\n",
    "    qml.CNOT(wires=[2,1])\n",
    "    qml.adjoint(qml.RY(params[8],wires=2))\n",
    "    qml.CNOT(wires=[1,2])\n",
    "    qml.adjoint(qml.RY(params[7],wires=2))\n",
    "    qml.adjoint(qml.RZ(params[6],wires=1))\n",
    "    qml.CNOT(wires=[2,1])\n",
    "    qml.adjoint(qml.U3(params[3],params[4],params[5],wires=2))\n",
    "    qml.adjoint(qml.U3(params[0],params[1],params[2],wires=1))\n",
    "\n",
    "    qml.QubitUnitary(proj, wires=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92344aad-63b5-4f43-b205-b6ce6065ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def bell_pair1(params,p):\n",
    "    qml.Hadamard(wires=0)\n",
    "    qml.CNOT(wires=[0,1])\n",
    "    qml.U3(params[0],params[1],params[2],wires=1)\n",
    "    qml.U3(params[3],params[4],params[5],wires=2)\n",
    "    qml.CNOT(wires=[2,1])\n",
    "    qml.RZ(params[6],wires=1)\n",
    "    qml.RY(params[7],wires=2)\n",
    "    qml.CNOT(wires=[1,2])\n",
    "    qml.RY(params[8],wires=2)\n",
    "    qml.CNOT(wires=[2,1])\n",
    "    qml.U3(params[9],params[10],params[11],wires=1)\n",
    "    qml.U3(params[12],params[13],params[14],wires=2)\n",
    "    qml.DepolarizingChannel(1-p,wires=1)\n",
    "    qml.DepolarizingChannel(1-p,wires=2)\n",
    "    qml.adjoint(qml.U3(params[12],params[13],params[14],wires=2))\n",
    "    qml.adjoint(qml.U3(params[9],params[10],params[11],wires=1))\n",
    "    qml.CNOT(wires=[2,1])\n",
    "    qml.adjoint(qml.RY(params[8],wires=2))\n",
    "    qml.CNOT(wires=[1,2])\n",
    "    qml.adjoint(qml.RY(params[7],wires=2))\n",
    "    qml.adjoint(qml.RZ(params[6],wires=1))\n",
    "    qml.CNOT(wires=[2,1])\n",
    "    qml.adjoint(qml.U3(params[3],params[4],params[5],wires=2))\n",
    "    qml.adjoint(qml.U3(params[0],params[1],params[2],wires=1))\n",
    "\n",
    "    qml.QubitUnitary(proj, wires=2)\n",
    "\n",
    "    return qml.density_matrix(wires=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d5ae3b6-65c4-4143-9827-1f6e087836c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_AB(dev, bell_pair, A, B):\n",
    "    @qml.qnode(dev)\n",
    "    def circuit(params,p):\n",
    "        bell_pair(params,p) \n",
    "        return qml.expval(qml.Hermitian(A, wires=0) @ qml.Hermitian(B, wires=1))\n",
    "    return circuit\n",
    "\n",
    "# Cost function\n",
    "def cost(params,p):\n",
    "    # Creating observables with new parameters\n",
    "    A1 = create_observable(0, 0)\n",
    "    A2 = create_observable(np.pi/2, 0)\n",
    "    B1 = create_observable(np.pi/4, 0)\n",
    "    B2 = create_observable(np.pi/4, np.pi)\n",
    "    trace=np.trace(bell_pair1(params,p))\n",
    "\n",
    "    expvals = [measure_AB(dev, bell_pair, A1, B1)(params,p)/trace,\n",
    "               measure_AB(dev, bell_pair, A1, B2)(params,p)/trace,\n",
    "               measure_AB(dev, bell_pair, A2, B1)(params,p)/trace,\n",
    "               measure_AB(dev, bell_pair, A2, B2)(params,p)/trace]\n",
    "    # trace=1 #np.trace(bell_pair1(params,p))\n",
    "    return -np.real((np.sum(expvals[:3]) - expvals[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b187e1d3-232f-48e9-8f9c-165a6a4f158e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam Fine-Tuning Step 1/100, Cost: -0.7712375860117111\n",
      "Adam Fine-Tuning Step 2/100, Cost: -0.8517952095154528\n",
      "Adam Fine-Tuning Step 3/100, Cost: -0.8626162610657673\n",
      "Adam Fine-Tuning Step 4/100, Cost: -0.8473495718356443\n",
      "Adam Fine-Tuning Step 5/100, Cost: -0.8489539063050713\n",
      "Adam Fine-Tuning Step 6/100, Cost: -0.8678356088189593\n",
      "Adam Fine-Tuning Step 7/100, Cost: -0.8862626179773551\n",
      "Adam Fine-Tuning Step 8/100, Cost: -0.8904080679813979\n",
      "Adam Fine-Tuning Step 9/100, Cost: -0.8816161214944607\n",
      "Adam Fine-Tuning Step 10/100, Cost: -0.8726900196865341\n",
      "Adam Fine-Tuning Step 11/100, Cost: -0.871975444876375\n",
      "Adam Fine-Tuning Step 12/100, Cost: -0.8781474173742017\n",
      "Adam Fine-Tuning Step 13/100, Cost: -0.8852936532005007\n",
      "Adam Fine-Tuning Step 14/100, Cost: -0.8883574851556006\n",
      "Adam Fine-Tuning Step 15/100, Cost: -0.886749168230897\n",
      "Adam Fine-Tuning Step 16/100, Cost: -0.8841299871176536\n",
      "Adam Fine-Tuning Step 17/100, Cost: -0.884083161922867\n",
      "Adam Fine-Tuning Step 18/100, Cost: -0.8867591769713129\n",
      "Adam Fine-Tuning Step 19/100, Cost: -0.8895974187526272\n",
      "Adam Fine-Tuning Step 20/100, Cost: -0.8901707768749669\n",
      "Adam Fine-Tuning Step 21/100, Cost: -0.888381107543909\n",
      "Adam Fine-Tuning Step 22/100, Cost: -0.8863022415624185\n",
      "Adam Fine-Tuning Step 23/100, Cost: -0.8860143992570815\n",
      "Adam Fine-Tuning Step 24/100, Cost: -0.8877554278898223\n",
      "Adam Fine-Tuning Step 25/100, Cost: -0.890020165611637\n",
      "Adam Fine-Tuning Step 26/100, Cost: -0.891128639201237\n",
      "Adam Fine-Tuning Step 27/100, Cost: -0.8907140219033798\n",
      "Adam Fine-Tuning Step 28/100, Cost: -0.8897964172629762\n",
      "Adam Fine-Tuning Step 29/100, Cost: -0.8895455834742625\n",
      "Adam Fine-Tuning Step 30/100, Cost: -0.8901679401456222\n",
      "Adam Fine-Tuning Step 31/100, Cost: -0.890942839256432\n",
      "Adam Fine-Tuning Step 32/100, Cost: -0.8911165828742909\n",
      "Adam Fine-Tuning Step 33/100, Cost: -0.8906666262541327\n",
      "Adam Fine-Tuning Step 34/100, Cost: -0.8902278157256929\n",
      "Adam Fine-Tuning Step 35/100, Cost: -0.8903603449091048\n",
      "Adam Fine-Tuning Step 36/100, Cost: -0.8909891175329359\n",
      "Adam Fine-Tuning Step 37/100, Cost: -0.891561765217727\n",
      "Adam Fine-Tuning Step 38/100, Cost: -0.8916590897581387\n",
      "Adam Fine-Tuning Step 39/100, Cost: -0.8913832295923316\n",
      "Adam Fine-Tuning Step 40/100, Cost: -0.89116275779322\n",
      "Adam Fine-Tuning Step 41/100, Cost: -0.8912556980916413\n",
      "Adam Fine-Tuning Step 42/100, Cost: -0.8915176289402742\n",
      "Adam Fine-Tuning Step 43/100, Cost: -0.8916391549318576\n",
      "Adam Fine-Tuning Step 44/100, Cost: -0.8915282297584681\n",
      "Adam Fine-Tuning Step 45/100, Cost: -0.8913945453966363\n",
      "Adam Fine-Tuning Step 46/100, Cost: -0.8914657577516077\n",
      "Adam Fine-Tuning Step 47/100, Cost: -0.8917056171138422\n",
      "Adam Fine-Tuning Step 48/100, Cost: -0.8918753046056372\n",
      "Adam Fine-Tuning Step 49/100, Cost: -0.8918336753758832\n",
      "Adam Fine-Tuning Step 50/100, Cost: -0.8916908169908478\n",
      "Adam Fine-Tuning Step 51/100, Cost: -0.8916431714143918\n",
      "Adam Fine-Tuning Step 52/100, Cost: -0.8917303492274324\n",
      "Adam Fine-Tuning Step 53/100, Cost: -0.8918230661471704\n",
      "Adam Fine-Tuning Step 54/100, Cost: -0.8918203539175978\n",
      "Adam Fine-Tuning Step 55/100, Cost: -0.8917738958052075\n",
      "Adam Fine-Tuning Step 56/100, Cost: -0.8917903577360374\n",
      "Adam Fine-Tuning Step 57/100, Cost: -0.8918738235427843\n",
      "Adam Fine-Tuning Step 58/100, Cost: -0.891928509944658\n",
      "Adam Fine-Tuning Step 59/100, Cost: -0.8918977277951814\n",
      "Adam Fine-Tuning Step 60/100, Cost: -0.8918356153089122\n",
      "Adam Fine-Tuning Step 61/100, Cost: -0.8918247297000164\n",
      "Adam Fine-Tuning Step 62/100, Cost: -0.8918692919370673\n",
      "Adam Fine-Tuning Step 63/100, Cost: -0.891907174261441\n",
      "Adam Fine-Tuning Step 64/100, Cost: -0.8919046704543991\n",
      "Adam Fine-Tuning Step 65/100, Cost: -0.8918935604625209\n",
      "Adam Fine-Tuning Step 66/100, Cost: -0.8919099831068458\n",
      "Adam Fine-Tuning Step 67/100, Cost: -0.8919374122591752\n",
      "Adam Fine-Tuning Step 68/100, Cost: -0.891936745820211\n",
      "Adam Fine-Tuning Step 69/100, Cost: -0.8919092611976416\n",
      "Adam Fine-Tuning Step 70/100, Cost: -0.8918944652896033\n",
      "Adam Fine-Tuning Step 71/100, Cost: -0.8919110789819654\n",
      "Adam Fine-Tuning Step 72/100, Cost: -0.8919341805027341\n",
      "Adam Fine-Tuning Step 73/100, Cost: -0.8919379764440509\n",
      "Adam Fine-Tuning Step 74/100, Cost: -0.8919315744405677\n",
      "Adam Fine-Tuning Step 75/100, Cost: -0.8919354784083537\n",
      "Adam Fine-Tuning Step 76/100, Cost: -0.8919455597286485\n",
      "Adam Fine-Tuning Step 77/100, Cost: -0.891943915507343\n",
      "Adam Fine-Tuning Step 78/100, Cost: -0.8919319628164797\n",
      "Adam Fine-Tuning Step 79/100, Cost: -0.8919281302432229\n",
      "Adam Fine-Tuning Step 80/100, Cost: -0.8919377292387876\n",
      "Adam Fine-Tuning Step 81/100, Cost: -0.8919468546337928\n",
      "Adam Fine-Tuning Step 82/100, Cost: -0.8919463942324443\n",
      "Adam Fine-Tuning Step 83/100, Cost: -0.8919436188011555\n",
      "Adam Fine-Tuning Step 84/100, Cost: -0.8919460047916266\n",
      "Adam Fine-Tuning Step 85/100, Cost: -0.8919488734491337\n",
      "Adam Fine-Tuning Step 86/100, Cost: -0.8919462095958397\n",
      "Adam Fine-Tuning Step 87/100, Cost: -0.8919423564961111\n",
      "Adam Fine-Tuning Step 88/100, Cost: -0.8919441718980876\n",
      "Adam Fine-Tuning Step 89/100, Cost: -0.8919491892328815\n",
      "Adam Fine-Tuning Step 90/100, Cost: -0.8919505352201971\n",
      "Adam Fine-Tuning Step 91/100, Cost: -0.8919484598191583\n",
      "Adam Fine-Tuning Step 92/100, Cost: -0.8919481888160234\n",
      "Adam Fine-Tuning Step 93/100, Cost: -0.8919499746275138\n",
      "Adam Fine-Tuning Step 94/100, Cost: -0.8919499457957312\n",
      "Adam Fine-Tuning Step 95/100, Cost: -0.8919483478494014\n",
      "Adam Fine-Tuning Step 96/100, Cost: -0.8919487893286397\n",
      "Adam Fine-Tuning Step 97/100, Cost: -0.8919510035528732\n",
      "Adam Fine-Tuning Step 98/100, Cost: -0.8919515538785796\n",
      "Adam Fine-Tuning Step 99/100, Cost: -0.8919502957570147\n",
      "Adam Fine-Tuning Step 100/100, Cost: -0.89194998121524\n",
      "CHSH: [-0.89194998121524]\n",
      "Params: [tensor([-2.99684120e-01, -8.53129750e-01, -8.61602068e-01,\n",
      "        -2.03523183e-03, -1.21435711e+00,  2.46593328e+00,\n",
      "         3.26217379e+00, -3.14389364e+00,  1.57097602e+00,\n",
      "         2.94402937e+00,  3.11194890e+00, -1.72812606e+00,\n",
      "         9.06950976e-01, -2.68593292e+00,  4.35254154e-01], requires_grad=True)]\n",
      "Prob_SUCESS: [(0.5355561301442225+3.7947076036992655e-17j)]\n"
     ]
    }
   ],
   "source": [
    "p_val =np.linspace(0.25,1,0.5)\n",
    "\n",
    "CHSH = []\n",
    "par = []\n",
    "Prob_SUCESS = []\n",
    "nstep = 500\n",
    "\n",
    "adam_opt = qml.AdamOptimizer(0.1)\n",
    "adam_steps = 100 \n",
    "\n",
    "for p in p_val:\n",
    "    # Initialize parameters\n",
    "    params = np.array(np.random.uniform(-np.pi, np.pi, 15), requires_grad=True)\n",
    "    \n",
    "\n",
    "    for i in range(adam_steps):\n",
    "        params, ccost = adam_opt.step_and_cost(lambda v: cost(v, p), params)\n",
    "        print(f\"step {i + 1}/{adam_steps}, Cost: {ccost}\")\n",
    "\n",
    "    # Calculate the success probability\n",
    "    PS = np.trace(bell_pair1(params, p))\n",
    "\n",
    "    # Store the result for this p_val\n",
    "    CHSH.append(ccost)\n",
    "    par.append(params)\n",
    "    Prob_SUCESS.append(PS)\n",
    "\n",
    "# Output the results\n",
    "print(\"CHSH:\", CHSH)\n",
    "print(\"Params:\", par)\n",
    "print(\"Prob_SUCESS:\", Prob_SUCESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98ee013e-2a8c-4148-a5c3-6a1b0c1c2cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [tensor(1.99699575, requires_grad=True), tensor(2.00598162, requires_grad=True), tensor(2.02460369, requires_grad=True), tensor(2.0581806, requires_grad=True), tensor(2.11178293, requires_grad=True), tensor(2.18644232, requires_grad=True), tensor(2.28227571, requires_grad=True), tensor(2.39369046, requires_grad=True), tensor(2.51868766, requires_grad=True), tensor(2.65319462, requires_grad=True), tensor(2.79724831, requires_grad=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2cc3297-1328-49b8-be72-aecf824a44e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_anat = [1.1313708498984758,1.365447577463678,1.5896999168281507,1.8007978925719688,1.9965367939384875,2.1757131728816845,2.3379484325936715,2.4834969875820208,2.613064653318815,2.7276518115129527,2.8284271247461903]\n",
    "f1num=[1.26277036,1.48416195,1.69116265,1.8823018,2.05786114,2.21824051,2.36447021,2.49840787,2.61949019,2.69858243,2.82842555]\n",
    "p1num=[0.5,0.5801684047848221,0.6089193863872889,0.6422274086134266,0.6800251336292099,0.7223578403515133,0.7691523517309242,0.8200857682076388,0.8756233266968312,0.9447131992968434,1.0000000000000533]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1081e58-a031-47cb-b869-aef5262b18b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ff1num=[1.131370849875084,1.3654475771792844,1.5896999166948438,1.800797892502143,1.996536293428982,2.1757103639895634,2.3379472097006033,2.48349622334479,2.6130640854024603,2.727651435832109,2.8284271247461215]\n",
    "fp1num=[0.555555555570983,0.580000000067194,0.6088888889081859,0.6422222222258873,0.6800001208192743,0.7222226034023373,0.7688892860072644,0.8200004643841046,0.8755557296409249,0.9355556033845127,1.0000000000000426]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
